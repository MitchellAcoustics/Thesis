\chapter{The Predictive Soundscape Model Framework}
\label{ch:bayes}

\section{Goals}
Before defining what form a general practical predictive model should take, we first need to make clear what the goals of such a model are. First, that it to a reasonable extent is successful in predicting the collective perception of a soundscape. As described in detail in \cref{ch:ProbabilisticPOC}, it should succeed at both indicating the central tendency of the soundscape perception, but importantly it should also inform the likely spread of perception among the population. The outcome of the predictive model should not be focussed on predicting an individual assessment; the goal is not to predict the perception of any specific individual, but to reflect the public's perception of a public space. In other words, ideally the model will result in an accurate distribution of soundscape perceptions for the target population. 

Second, that it can be implemented automatically. Once an initial setup is performed, such as identifying what location the measurements are conducted in, the model should be capable of moving from recorded information to predicted soundscape distribution without human intervention. We need soundscape assessments to be able to be performed instrumentally. This enables it to be applied to unmanned uses, such as smart city sensors and soundscape mapping. It is impractical to conduct soundscape surveys or soundwalks in every location we wish to map and certainly not when we wish to see how these locations change over longer periods of time. A predictive model should allow us to survey these soundscapes remotely in order to extend soundscape to city-scale assessments. 

Third, the model should enable us to test and score proposed interventions. In a design context, it is crucial that various design strategies and interventions can be tested and that the influencing factors can be identified. The model should assist the user in highlighting what factor is limiting the success of a soundscape, spark ideas for how to address it, and allow these ideas to be tested. Several other useful features of predictive soundscape models arise out of these goals and will be discussed later, but these form the core goals of the framework.

\section{Constraints}
\label{sec:modelConstraints}
If we accept that predictive models are necessary to advance a more holistic approach to urban sound in smart cities, we must then define the constraints of such a model. The goal here is to define a framework for what is needed from a future model intended to be used in a smart city sensors, soundscape mapping, or urban design context.

The first constraint is that the model must be based on measurable factors. By this, I mean the data which eventually feeds into the predictive model should be collected via sensor measurements of one sort or another; this could be acoustic sound level measurements or recordings, environmental measurements, video recordings, or GIS measurements, etc.. What it certainly cannot include is perceptual data. This is strictly a practical constraint - for a predictive model designed to be used in practice, there is no justification to include other perceptual factors, such as perceived greenness, derived from surveys but not whichever factor you desire to predict. If the goal is to predict soundscape pleasantness and it is necessary to survey people about the visual pleasantness, why not just also survey them about the soundscape pleasantness directly? Certainly this mix of perceptual data is useful in research and can elucidate the relationships between the sonic and visual environments, but it is not useful in a practical predictive context. Any results which arise from research combining this sort of perceptual information must eventually be translated into a component which can itself be measured or modelled.

The second constraint is that any analysis of the measured data can be done automatically, without human intervention. If the eventual goal is to deploy the model on continuously-running, unmanned sensor nodes or to enable practical large-scale measurements, the predictive model should be capable of operating with minimal human input. This means, for instance, that if the model includes information about the sound source, this identification of the source should be possible to do automatically (i.e. through environmental sound recognition). Towards this goal, and given the current practical limitations of environmental sound recognition, a model using a manually-labelled sound-source data is used in \cref{ch:mlmann} to investigate the future potential of sound-source aware prediction models.

The third constraint is for the model to be generalisable to new locations. Ideally, it will be generalisable to new and (to it) unfamiliar soundscape types, but the minimum requirement should be that it can be applied to new locations which are otherwise similar to those in the training data. This means that any factors which are used to characterise the context provided by the location should be distinguished from a simple label of the location and should instead be derived from measurements of the location. In practice this could be geographical or architectural characteristics of the space, a proposed use-case of the space, or consistent visual characteristics of the space such as the proportion of pavement to green elements. This is in contrast to the model created for \cref{ch:lockdown} which was constrained to be used only on those locations included in the training data since it made use of a location label.

For this third point, some aspects of the first and second constraints can be relaxed. Since this would only need to be defined once for a location, definitions such as the use case of the space could be defined by the person using the model. What is necessary is that the model and its component location-context factors can be set up ahead of time by the user, then the recording-level effects are able to be calculated automatically. In the MLM context this essentially amounts to choosing the appropriate location-level coefficients ahead of time then automatically calculating the features which are fed into those coefficients (per constraint 1 \& 2).

A potential constraint for some applications is related to computation time. Since one proposed application of a predictive soundscape model is to embed the model on a \gls{wasn} node, the model would then need to be able to run on relatively low-power hardware such as a Raspberry Pi with a reasonable latency. This would especially present an issue for a model which relies on the combination of several psychoacoustic features, such as that in \cref{ch:lockdown}, since these features are computationally intensive to calculate and several of them may need to be computed for each time step of the model. Although this is a real practical concern that should be addressed in the future, for the sake of this initial definition of a general predictive model used across many applications, I have not considered this as a strict constraint. The model being developed here would primarily be intended to operate as an off-line design tool operating on standard desktop hardware and not necessarily requiring real-time calculations. In the case of a \gls{wasn}, a model of this sort could still be used by sending recording information from the node to a central computer for further computation and analysis. Further efficiency improvements and a specific algorithm for embedding on the node is left as a future development.

Finally, the model should be robust to missing components. If the original or full construction of the model depends on demographic information of the population using the space, in cases where this information is not available, it should be possible to omit it and still obtain a reasonable result. Here we may define potential `must-have’ and `optional’ factors. Given the amount of variance explained by the various factors explored in this thesis, in-depth acoustic information is a must-have, while demographic and personal factors are an optional factor where the trade-off of losing 3\% of the explained variance in eventfulness (as will be shown in \cref{ch:whostudy}) is accepted as reasonable. Based on the results of \cref{ch:lockdown}, it would appear that location-context is crucial for modelling the pleasantness, but not for modelling the eventfulness. In order to determine the must-have factors for characterising the location-context, more work will need to be done to determine the appropriate input factors and their relative importance. 

\section{Expansions and advancements for future predictive models}

To illustrate how a model which fits this proposed framework could be developed, I will start with the model presented in \cref{ch:lockdown}. As it is, this model most obviously violates constraint 3 - it is not generalisable to new locations. Since the structure of the \gls{mlm} has the `LocationID' as the categorical feature used in the second level, any new data must be able to conform to one of the original 13 locations. Technically, it would be possible to select the location in the training data which is considered most similar to the new location and use the coefficients derived for it, but this is a poor design for a generalisable model. Therefore the first stage to generalise this starting point model would be to replace the location-label variable with a more general categorical description of the location-context.

\subsection{Incorporating architectural and visual information}

The simplest version of this replacement would be to sort the locations into a predefined architectural or landscape location type. \citet{Suligowski2021Quantity} presents a definition in which urban spaces can be classed as `green' (unsealed, permeable, biologically active areas), `blue' (water areas), or `grey' (human made, predominantly formed by sealed, impermeable, hard surfaces built from concrete or tarmac). Thus we could sort the 13 locations used in the model according to whether they would be classed as green, blue, or grey and reconstruct the multilevel model using these categories in place of the location labels. In this way, new locations could then be similarly identified and fed into the model.

However, this simplified method has a few potential drawbacks. The green-blue-grey classification likely would not capture a wide enough array of potential landscape or architectural types and therefore would limit the ability of the model to differentiate the varying relationships between the acoustic features and the soundscape perception. In addition, the green-grey-blue paradigm does not provide an indication of the visual quality of the space. Although it might be assumed that green spaces are visually pleasant and grey spaces less so, there would presumably be some spectrum of quality within each of these categories which may provide additional information for the prediction of soundscape quality.

An alternative method is to make use of the visual information about the locations which can be capture as part of the \gls{ssid} protocol. The most straightforward method for this is to make use of a clustering algorithm to analyse measured features of the spaces and sort a given location into one of several location types. From a visual analysis model such as the FaceLift model presented by \citet{Joglekar2020Facelift}, it is possible to extract elements such as the percent of visible sky (i.e. openness), the percent of greenness, and an overall visual quality rating from photos and videos taken in the space. By applying an unsupervised clustering algorithm to this visual data, many more categories of the architectural and visual characteristics of the space can be derived and measurements of new spaces can likewise be assigned to these categories. 

With this method, we would then have a two-stage model, where the first stage is to measure the visual characteristics of the space and, using the clustering algorithm, sort it into one of the identified categories. This category would be assigned to all subsequent acoustic measurements taken in the space as they are fed into the \gls{mlm} to predict the likely soundscape assessment.

This analysis method was demonstrated briefly in \cref{ch:lockdown} in order to create three clusters based on the measured acoustic features. However, since the goal is to make use of the visual features and to introduce additional contextual information in a useful way, it does not seem useful to expand this clustering based on acoustic features, which would be directly used in the model in any case. In practice, the necessary information to perform this clustering based on visual features is already present in the \gls{isd} in the form of the 360\textdegree video recordings. A demonstration of this approach has not been included in this thesis due to time and technological constraints involved in processing the visual features of the recording and is left for future work. 

\subsection{Additional acoustic, psychoacoustic, and bioacoustic metrics}

Although the model presented in \cref{ch:lockdown} began its feature selection with a relatively wide array of potential psychoacoustic features, many aspects of the sound were not captured and many potential metrics were not included. This includes additional statistical breakdowns of the included features - for instance, \gls{la90} (as a measure of the background level), $N_{10} - N_{90}$, $L_{A,max}$ and $L_{A,min}$, etc. There are also a host of bioacoustic metrics which were not considered, such as those presented in \citet{Devos2016Soundecology}, including the Acoustic Complexity Index (ACI), Normalized Difference Soundscape Index (NDSI), Bioacoustic Index (BIO), and so on.

An important sonic feature which is underutilised is the temporal behaviour of the sound. A few metrics are able to capture some aspects of how the sound changes over time, such as \gls{fs} looking at amplitude modulations in the sub-audible range, but this is still limited. One approach to characterising the temporal structure of complex acoustic scenes is through $1/f$ analysis \citep{deCoensel20031f,deCoensel2006quiet,Yang2015Presence}. An initial exploration of this metric and its potential for predicting soundscape perception was presented in \citet{Mitchell2019spectral} and in \cref{app:overf}. Future work on expanding the predictive model should begin by considering these additional metrics and exploring their potential as new and better-performing input features for predicting soundscape perception.

With this increased slate of potential input parameters, a more efficient feature selection method will need to be employed, compared to the stepwise feature selection used throughout this thesis. The multicollinearity between the candidate features, the increased training time, and the ratio between independent variables and sample size make it infeasible to apply a stepwise selection with a large number of candidate features. Approaches for this would likely begin with filtering features according to their correlation coefficients, or by using a nonlinear alternative, such as mutual information (the reduction in uncertainty due to another random variable) \citep{Cover1991}. Given the multilevel nature of the data and model, I would recommend using a multilevel or partial correlation coefficient \citep{Baba2004Partial} or conditional mutual information \citep{Fleuret2004Fast} which can account for the influence of a third variable. 

\paragraph*{}
In this chapter I have defined a framework for developing predictive soundscape models which can be put to use in engineering, design, and soundscape mapping contexts. Of the goals and subsequent constraints raised, the two which should be prioritised and underly any future work in the field are the ability to automate processing in a deployed model and including only measurable, estimate-able, or modelled inputs. Keeping these goals in mind, there are several steps which can be taken to improve the accuracy and generalisability of our first-step model. The following chapters will present in depth studies which have been undertaken to address two of these developments and the developments briefly discussed in this chapter are proposals for options which are not addressed by the following studies. The next chapter presents how I have begun to incorporate the semantic meaning which listeners attach to certain sources using data collected via a \gls{wasn}.